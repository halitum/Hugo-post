+++
title = "[Datawhale机器学习教程] 1. 机器学习绪论"
date = "2024-09-18"
description = "概览西瓜书+南瓜书第1、2章"
tags = [
 "机器学习",
]
categories = [
 "DataWhale组队学习",
]
image = "https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240919004621136.png"

+++



> *一些基本概念*
>
> - 机器学习：研究关于“学习算法”的学科
> - 模型：从数据中学习得到的结果
> - 特征向量/示例：数据集中的每条记录
> - 特征(feature)/属性(attribute)：反应事件或对象在模仿门面的表现或性质的事项（属性的取值即为属性值，张成的空间为属性空间/样本空间）

## # 什么是假设空间？

假设空间是机器学习中用于描述所有**可能假设**的集合，我们试图在这个假设空间中寻找一个或多个与训练数据一致的假设，以便能够对未知数据进行准确的预测。

![image-20240919002408070](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240919002408070.png)

假设空间中与训练集一致的“假设集合”，称为**“版本空间”**。版本空间表示了在现有数据下，所有可能正确的模型集合。*学习的目标是缩小版本空间，理想情况下找到唯一的假设。*



## # 什么是归纳偏好(Inductive Bias)？

归纳偏好是学习过程中，对某种类型的假设所表现出的倾向，决定了机器学习算法选择哪个假设来构建模型（在训练数据不足以唯一确定模型时，归纳偏好帮助算法选择一个看起来最“正确”的假设。）

归纳偏好让算法在等效的假设中做出决策，选择出一个最适合的假设。所谓最适合的假设，就是最符合我们设定的原则的假设

> 常见的**归纳偏好原则**
>
> - 奥卡姆剃刀原则：若有多个假设与观察一致，则选最简单的那个
> - 平滑性假设：认为相似的输入应有相似的输出
> - 最大似然原则：选择使观测数据概率最大的假设

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240919003325192.png" alt="image-20240919003325192" style="zoom:50%;" />

在这个例子中，如果A、B曲线都是符合观察的版本空间，那么如果遵循奥卡姆剃刀原则作为归纳偏好原则，那我们最终将决定使用曲线A的假设空间来构建模型



## # “**没有免费的午餐**”定理（ **NFL** 定理）

内容：当所有“问题”出现的机会相同、或所有问题同等重要时，对于任意两个学习算法而言，他们的期望性能都相同。（但是，所有问题的先验概率是均匀的，这在现实中并不成立。而正相反，数据会具有特定的分布，算法可以利用这些分布特性取得更好的性能）

结论：谈论算法的相对优劣，必须要针对具体的学习问题



## # 机器学习应用领域

- **图像识别**：用于人脸识别、手写数字识别、自动驾驶中的物体检测等。
- **自然语言处理**：包括机器翻译、情感分析、文本分类、语音识别和生成等。
- **推荐系统**：在电商平台推荐商品，在音乐和视频平台推荐内容，提高用户体验。
- **金融预测**：用于股票价格预测、信用评分、欺诈检测和风险管理。



## # 模型评估与选择

![](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/%E6%AC%A0%E6%8B%9F%E5%90%88%E5%92%8C%E8%BF%87%E6%8B%9F%E5%90%88png.png)

（欠拟合-高偏差 、正常拟合 、过拟合-高方差）

欠拟合比较容易解决，增大神经网络学习轮数/扩展决策树分支即可，过拟合则难以克服。实际上，过拟合是无法彻底避免的，而只能被缓解

### #评估方法

使用模型在“测试数据”上的误差（测试误差(testing error)）来近似作为模型泛化能力的误差

> 从一整个数据集中划分测试集与训练集的方法：
>
> - 留出法：直接将数据集D 划分为两个互斥的集合。（为避免单次留出得到的估计结果不稳定可靠，往往要进行p次随机划分，最终的评估结果是这p次训练-测试结果的均值）
>   - 交叉验证法：将数据集划分为K个大小相似的互斥子集（k折交叉验证）——1折验证，k-1折训练，轮替进行，最终的评估结果是这p次k折交叉验证结果的均值（一共进行了p*k次训练-测试）
> - 自助法（有放回采样）：从数据集中pick m次（样本可能被重复pick），将pick到的数据m个数据作为训练集，原数据集种未被pick到的样本点作为测试集。可以避免训练样本规模不同而导致的估计偏差，数据集较小、难以有效划分训练／测试集时很有用。自助法的缺点是，产生的数据集会改变初始数据集的分布

   ```mermaid
   graph LR
       A[数据集] --> B[训练数据]
       A --> C[测试数据]
       B --> D[训练集 training set]
       B --> F[验证集 validation set]
       C --> E[测试集 testing set]
       E --> G[用来测试模型泛化能力]
       D --> H[用来训练模型]
       F --> I[用来验证算法能力]
   ```

**性能度量**

* 准确率（precision）度量的是被预测为正例的样本中有多少是真正的正例

* 精确率（Precision）预测为正类的样本中，实际为正类的比例

* 召回率（recall）度量的是正类样本中有多少被预测为正类

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240322170518905.png" alt="image-20240322170518905" style="zoom: 33%;" />

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240921230119206.png" alt="image-20240921230119206" style="zoom:50%;" />

**ROC曲线（Receiver Operating Characteristic curve）**

内容是真正类率（True Positive Rate, TPR）（就是指召回率）和假正类率（False Positive Rate, FPR）之间的关系

> 假正类率（FPR）
>
> 模型错误地将负类识别为正类的比例 FPR = FP / (FP + TN)

![roc](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/roc.png)

ROC曲线面积（AUC值）越大模型的性能越好
