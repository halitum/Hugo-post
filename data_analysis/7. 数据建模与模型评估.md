+++
title = "数据分析笔记（七）"

date = "2024-03-28"

description = "7. 数据建模与模型评估"

tags = [

 "",

]

categories = [

 "数据分析",

]

image = ""

+++

> **Seaborn**
> 基于Matplotlib的数据可视化库，是Matplotlib的补充而非替代

> **Scikit-learn** (简称 sklearn)
>
> 一个机器学习库。基于 NumPy、SciPy 和 matplotlib 。用于数据挖掘和数据分析

> **机器学习任务分类**
>
> - 监督学习：从标记的训练数据进行学习
> - 无监督学习：从未经标记或分类的数据进行学习

机器学习算法模型选择：

![](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95%E9%80%89%E6%8B%A9%E8%B7%AF%E5%BE%84.png)

刚开始我们总是先尝试使用一个基本的模型来作为其baseline，进而再训练其他模型做对比，最终选择泛化能力或性能比较好的模型

> **数据拟合**
>
> - 一项统计学技术，用来找到最佳的函数模型，来描述两个或多个变量之间的关系
> - 可以用来理解变量之间的相互作用，预测未来的数据点，以及对模型的预测能力进行评估

![](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/%E6%AC%A0%E6%8B%9F%E5%90%88%E5%92%8C%E8%BF%87%E6%8B%9F%E5%90%88png.png)

（欠拟合-高偏差 、正常拟合 、过拟合-高方差）

> **正则化**
>
> 一种用来防止模型过拟合的技术，通过在损失函数中添加一个惩罚项来实现。这个惩罚项会惩罚模型的复杂度，通常与模型参数的大小有关
>
> 正则化主要使用在逻辑回归、支持向量机（SVM）等线性模型中



## 模型搭建步骤：

1. 设定自变量和因变量

   - 自变量（x）：模型输入，对结果的影响因素

   - 因变量（y）：模型输出，想要预测的对象

     ```py
     X = data
     y = train['Survived']
     ```

2. 划分训练集和测试集

   ```mermaid
   graph LR
       A[数据] --> B[训练数据]
       A --> C[测试数据]
       B --> D[用来学习 获取参数]
       B --> F[又叫监督数据]
       C --> E[用来评价模型能力]
   ```

   - 划分作用：价模型泛化能力——处理未被观察过的数据的能力

   - sklearn中切割数据集的方法为`train_test_split`（默认测试集占总数据量25%）

     ```py
     X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)
     ```

3. 模型选择

   - **逻辑回归模型**

     - 基于线性模型的分类模型（主要用于二分类问题）

     - 是一种线性分类器（利用sigmoid计算概率），因此难以拟合非线性关系的数据；模型易受离群点影响，需要事先进行数据清洗

     - 实现（scikit-learn）

       ```py
       # 导入lr模型
       from sklearn.linear_model import LogisticRegression
       # 创建逻辑回归模型
       model = LogisticRegression()
       # 训练模型
       model.fit(X_train, y_train)
       # 预测测试集
       predictions = model.predict(X_test)
       # 查看score
       print("Training set score: {:.2f}".format(lr.score(X_train, y_train)))
       print("Testing set score: {:.2f}".format(lr.score(X_test, y_test)))
       ```
     - 调参

       - **`C`**：较小表示正则化越强，默认为1
       - **`max_iter`**：求解器的最大迭代次数。增大可以帮助模型收敛
       - **`class_weight`**：指定类别权重

   - **随机森林模型**

     - 基于树的分类模型(除了分类也可用于回归任务)
     - 一种集成学习方法，它通过构建多个决策树（森林）并输出模式（分类）或平均预测（回归）的方式来工作

     > 决策树：一个预测模型
     >
     > <img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/%E5%86%B3%E7%AD%96%E6%A0%91.png" style="zoom:50%;" />

     - 实现（scikit-learn）

       ```py
       # 导入lr模型
       from sklearn.linear_model import RandomForestClassifier
       # 默认参数的随机森林分类模型
       rfc = RandomForestClassifier()
       rfc.fit(X_train, y_train)
       # 输出score
       print("Training set score: {:.2f}".format(rfc.score(X_train, y_train)))
       print("Testing set score: {:.2f}".format(rfc.score(X_test, y_test)))
       ```
     
     - 调参
       - **`n_estimators`**：森林中树的数量（默认为100）。增大可以用计算成本（性能）换取模型稳定性和准确性
       - **`max_depth`**：树的最大深度。过小容易欠拟合，过大容易过拟合
       - **`min_samples_split`**：分裂内部节点所需的最小样本数（默认为2）。增大可以避免过拟合
       - **`min_samples_leaf`**：叶节点所需的最小样本数。增大可以防止过拟合

4. 通用调参

   1. 正则化处理（使用penalty参数来指定正则化项的类型）

      1. L1正则化（penalty='l1'）

         - 将参数的绝对值之和加到原始损失函数上

         - 很多参数会被压缩到0，仅保留少数权重较大的特征

         - 使得模型更加简单，有助于解释和理解

      2. L2正则化（penalty='l2'）

         - 将参数的平方和加到原始损失函数上

         - 倾向于惩罚较大的参数，使得所有参数都被适度缩小，但不会完全缩小到0

         - 有助于处理特征之间的共线性问题，提高模型的稳定性

   2. 网格搜索：尝试参数的多个组合，并通过交叉验证来评估每种组合的性能，从而找到最佳参数



## 模型评估

> 模型评估是为了知道模型的泛化能力

### 1.  交叉验证（cross-validation, CV）

用来评估泛化性能，限制过拟合

在k 折交叉验证（k-fold cross-validation），数据被划分为k部分（k通常取 5 或 10），每次取其中一部分为测试集，其他部分为训练集，共训练k次（提高k用计算成本换取模型稳定性和准确性）。最终的模型性能是这K次评估结果的平均值

![](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.png)

**代码实现**：交叉验证使用sklearn.model_selection中的cross_val_score函数

```py
from sklearn.model_selection import cross_val_score

lr = LogisticRegression(C=100)
scores = cross_val_score(lr, X_train, y_train, cv=10)
# 平均交叉验证分数
print("Average cross-validation score: {:.2f}".format(scores.mean()))
```



### 2.  混淆矩阵

一种模型评估工具

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240322170518905.png" alt="image-20240322170518905" style="zoom: 33%;" />

* 准确率（precision）度量的是被预测为正例的样本中有多少是真正的正例

* 精确率（Precision）预测为正类的样本中，实际为正类的比例

* 召回率（recall）度量的是正类样本中有多少被预测为正类

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B50.png" style="zoom:50%;" />

- F-分数是准确率与召回率的调和平均，用于综合考虑精确率和召回率

  > f-的意义是在某些情况下准确率与召回率间存在冲突，需要对他们综合考虑来评判模型性能

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240322172824512.png" alt="image-20240322172824512" style="zoom:67%;" />

混淆矩阵主要应用于分类任务（尤其是在二分类）。可以用来理解模型在预测不同类别时的表现，尤其是在**数据集类别不平衡**时，以及在某些场景下模型对于少数类的准确预测通常比整体准确率更重要时。

**代码实现**：sklearn.metrics中的confusion_matrix()函数

> 精确率、召回率以及f-分数可使用`classification_report`模块

```py
from sklearn.metrics import confusion_matrix
# 训练模型
lr = LogisticRegression(C=100)
lr.fit(X_train, y_train)
# 模型预测结果
pred = lr.predict(X_train)
# 混淆矩阵
confusion_matrix(y_train, pred)
```

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240322173119425.png" alt="image-20240322173119425"  />

```py
from sklearn.metrics import classification_report
# 精确率、召回率以及f1-score
print(classification_report(y_train, pred))
```

<img src="https://typora-picturelib.oss-cn-beijing.aliyuncs.com/image-20240322173142830.png" alt="image-20240322173142830" style="zoom:67%;" />



### 3. ROC曲线（Receiver Operating Characteristic curve）

用于对混淆矩阵信息的可视化。内容是真正类率（True Positive Rate, TPR）（就是指召回率）和假正类率（False Positive Rate, FPR）之间的关系

> 假正类率（FPR）
>
> 模型错误地将负类识别为正类的比例 FPR = FP / (FP + TN)

**代码实现**：sklearn.metrics中的roc_curve()函数

```py
fpr, tpr, thresholds = roc_curve(y_test, lr.decision_function(X_test))
plt.plot(fpr, tpr, label="ROC Curve")
plt.xlabel("FPR")
plt.ylabel("TPR (recall)")
# 找到最接近于0的阈值
close_zero = np.argmin(np.abs(thresholds))
plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label="threshold zero", fillstyle="none", c='k', mew=2)
plt.legend(loc=4)
```

![roc](https://typora-picturelib.oss-cn-beijing.aliyuncs.com/roc.png)

ROC曲线面积（AUC值）越大模型的性能越好

> 多分类问题下的ROC曲线：
>
> - 一对多（One-vs-All）：对于每个类别，将其视为正类，其他所有类别视为负类（如果有N个类别，就会有N条ROC曲线）
> - 一对一（One-vs-One）：每对组合都可以绘制一个ROC曲线（共有N(N-1)/2条曲线）

ROC曲线用来识别模型在哪些类别上表现不佳，进而进行针对性的改进